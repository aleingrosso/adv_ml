{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0ff01ad-c268-48cc-8279-d6016fe77973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf69bf-34c5-4976-8b29-d6d694c7ee5e",
   "metadata": {},
   "source": [
    "# Lecture 2.1: Markov processes\n",
    "\n",
    "* Intro to Markov Chain Monte Carlo\n",
    "* Markov processes, stationary distribution and ergodicity\n",
    "\n",
    "MacKay, **Chapter 29**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2672b3-34f1-4cd0-b0a5-230de58f7c18",
   "metadata": {},
   "source": [
    "# Markov Chain Monte Carlo: the general idea with three examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a325e2-6b9c-4241-956b-c7dd6f38aaf1",
   "metadata": {},
   "source": [
    "#### Example of a Markov process in 2 dimension: a refresher on diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b2647c-6b59-4f2d-93f1-8ecfc9caf325",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.5\n",
    "num_steps = 5\n",
    "xlim = 4\n",
    "np.random.seed(12) # choose a seed (this is not an appropriate seed)\n",
    "\n",
    "# start from the origin and generate the next point using an isotropic Gaussian step in 2 dimensions\n",
    "_, _, xgrid_stacked = get_wgrid(wlim=xlim, num=100)\n",
    "xs = np.zeros((num_steps, 2))\n",
    "x = np.zeros(2) # start at zero\n",
    "fig, axes = plt.subplots(num_steps, figsize=(12,2 * num_steps))\n",
    "for t in range(num_steps):\n",
    "    pgrid = multivariate_normal(x, np.eye(2) * eps**2).pdf(xgrid_stacked)\n",
    "    xs[t] = x\n",
    "    x += np.random.randn(2) * eps # add a random gaussian at each time-step\n",
    "    handle = axes[t]\n",
    "    handle.set_xlim([-xlim,xlim])\n",
    "    handle.set_ylim([-xlim,xlim])\n",
    "    handle.set_aspect(\"equal\")\n",
    "    handle.plot(xs[:,0], xs[:,1], '.-', lw=0.5, c='black')\n",
    "    handle.imshow(pgrid, origin=\"lower\", extent=[-xlim,xlim,-xlim,xlim], alpha=0.6)\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603d9648-931f-4082-8425-5a55c491fee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a bunch of random walks in D dimension and check the sqrt scaling for distances\n",
    "D = 2\n",
    "eps = 1e-1\n",
    "samples = 100\n",
    "num_steps = 1000\n",
    "\n",
    "np.random.seed(42) # choose a seed (this is an appropriate seed [1])\n",
    "\n",
    "X = np.cumsum(np.random.randn(samples, D, num_steps), -1) * eps # a faster way to generate multiple trajectories at once\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "sample = 1\n",
    "plt.plot(X[sample,0,0], X[sample,1,0], 'o', ms=4, color=\"black\", label=\"start\");\n",
    "plt.plot(X[sample,0,:], X[sample,1,:], alpha=0.7, color=color_cycle[0]);\n",
    "plt.plot(X[sample,0,-1], X[sample,1,-1], 'x', ms=6, color=\"black\", label=\"end\");\n",
    "plt.plot([X[sample,0,0], X[sample,0,-1]], [X[sample,1,0], X[sample,1,-1]], '--', color=\"gray\", alpha=1);\n",
    "plt.legend();\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot((X[:10]**2).sum(1).T, alpha=0.3);\n",
    "plt.plot((X**2).sum(1).mean(0), c='black', label=\"average\")\n",
    "plt.plot(np.arange(num_steps), eps**2 * D * np.arange(num_steps), '--', c='black', label=r\"$d^2 \\propto t$\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend();\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b27ba05-f750-4e20-9275-a80bef431222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the marginal distribution over time\n",
    "i = 0\n",
    "for it, t in enumerate(np.linspace(20, num_steps-1, 5)):\n",
    "    t = int(t)\n",
    "    plt.hist(X[:,i,t], bins=50, density=True, alpha=0.5, color=color_cycle[it]);\n",
    "    xs = np.linspace(-5*eps*np.sqrt(t),5*eps*np.sqrt(t), 100)\n",
    "    plt.plot(xs, np.exp(-0.5/(eps**2*t)*xs**2)/np.sqrt(2*np.pi*eps**2*t), c=color_cycle[it], label=f\"t = {t}\");\n",
    "plt.legend(); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1822ff3-536a-4ba1-8bfe-4ac2331ad5b9",
   "metadata": {},
   "source": [
    "#### A Markov process converging to a prescribed distribution #1: the Ornstein-Uhlenbeck process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d07765e-9497-4add-9c83-1722618d2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's run an OU process starting from a delta initial condition\n",
    "sigma = 0.1\n",
    "k = 0.7\n",
    "dt = 0.1\n",
    "num_samples = 5000\n",
    "num_steps = 500\n",
    "\n",
    "# run a bunch of trajectories in parallel\n",
    "x0 = 0.5\n",
    "xs = np.zeros((num_steps, num_samples))\n",
    "x = np.ones(num_samples) * x0\n",
    "for t in range(num_steps):\n",
    "    xs[t] = x\n",
    "    x = (1 - dt * k) * x + np.sqrt(dt) * sigma * np.random.randn(num_samples)\n",
    "\n",
    "# plot the initial steps of some trajectories\n",
    "plt.plot(xs[:200,:10], '.-', alpha=0.1, c='black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06848248-1bc5-4591-9c82-5cbfc00dc9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.arange(num_steps) * dt\n",
    "expkts = np.exp(-k * ts)\n",
    "mean = x0 * expkts\n",
    "var = 0.5*sigma**2/k * (1-expkts**2)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(xs.mean(-1), label='av data')\n",
    "plt.plot(mean, label='av theory')\n",
    "plt.legend();\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(xs.var(-1), label='var data')\n",
    "plt.plot(var, label='var theory')\n",
    "plt.legend();\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea82ee0-88aa-4a71-b793-3f08cdd41830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize evolution of probability over states\n",
    "num_to_show = 10\n",
    "t_to_show = np.logspace(0, np.log10(num_steps), num_to_show, dtype=int) - 1\n",
    "\n",
    "fig, axes = plt.subplots(num_to_show, figsize=(4, 2 * num_to_show))\n",
    "x_to_plot = np.linspace(-1, 1, 1000)\n",
    "for i, t in enumerate(t_to_show):\n",
    "    axes[i].hist(xs[t], bins=100, density=True, alpha=0.5, label='data');\n",
    "    axes[i].plot(x_to_plot, multivariate_normal(mean[t], var[t]+1e-5).pdf(x_to_plot), label='theory');\n",
    "    axes[i].set_xlim([-1, 1])\n",
    "    axes[i].set_title(f't = {t}')\n",
    "    axes[i].set_xlabel('x')\n",
    "    axes[i].set_ylabel('p(x)');\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ada03a-7515-4d13-8286-bdaad7d32554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run it again from a more complicate distribution of initial conditions\n",
    "sigma = 0.1\n",
    "k = 0.7\n",
    "dt = 0.1\n",
    "num_samples = 5000\n",
    "num_steps = 500\n",
    "\n",
    "# run a bunch of trajectories in parallel\n",
    "xs = np.zeros((num_steps, num_samples))\n",
    "\n",
    "x = 0.05 * np.random.randn(num_samples) + 2 * np.concatenate([-np.ones(num_samples//2), np.ones(num_samples//2)])\n",
    "for t in range(num_steps):\n",
    "    xs[t] = x\n",
    "    x = (1 - dt * k) * x + np.sqrt(dt) * sigma * np.random.randn(num_samples)\n",
    "\n",
    "# plot the initial steps of some trajectories\n",
    "plt.plot(xs[:100,:10], '.-', alpha=0.1, c='black');\n",
    "plt.plot(xs[:100:,-10:], '.-', alpha=0.1, c='black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec95ef2-6e0c-479a-bbe6-0694ec7e1bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize evolution of probability over states\n",
    "num_to_show = 10\n",
    "t_to_show = np.logspace(0, np.log10(num_steps), num_to_show, dtype=int) - 1\n",
    "\n",
    "fig, axes = plt.subplots(num_to_show, figsize=(4, 2 * num_to_show))\n",
    "x_to_plot = np.linspace(-3, 3, 100)\n",
    "for i, t in enumerate(t_to_show):\n",
    "    axes[i].hist(xs[t], bins=100, density=True, alpha=0.5, label='data');\n",
    "    if t == t_to_show[-1]:\n",
    "        axes[i].plot(x_to_plot, multivariate_normal(mean[t], var[t]+1e-5).pdf(x_to_plot), label='theory');\n",
    "    axes[i].set_xlim([-3, 3])\n",
    "    axes[i].set_title(f't = {t}')\n",
    "    axes[i].set_xlabel('x')\n",
    "    axes[i].set_ylabel('p(x)');\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18219b8-a18e-4b00-ad11-5ea8cfc3d221",
   "metadata": {},
   "source": [
    "#### A Markov process converging to a prescribed distribution #2: the Metropolis-Hastings transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4361e2f7-45a6-4633-aba4-c0beec33d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "eps = 0.5\n",
    "xlim = 5\n",
    "_, _, xgrid_stacked = get_wgrid(wlim=xlim, num=200)\n",
    "distrib_to_sample = multivariate_normal(np.zeros(2), np.eye(2) * sigma**2)\n",
    "pgrid_to_sample = distrib_to_sample.pdf(xgrid_stacked)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(pgrid_to_sample, extent=[-xlim,xlim,-xlim,xlim], alpha=0.6, origin=\"lower\");\n",
    "plt.xlabel('x')\n",
    "plt.xlabel('y')\n",
    "plt.title(\"p(x)\")\n",
    "\n",
    "plt.subplot(122)\n",
    "x = np.array([3,-1])\n",
    "# x = np.array([0,3]) # try some other points to see how transition points towards typical regions of the distribution\n",
    "distrib_proposal = multivariate_normal(x, np.eye(2) * eps**2)\n",
    "pgrid_proposal = distrib_proposal.pdf(xgrid_stacked)\n",
    "\n",
    "q = np.minimum(np.ones_like(pgrid_to_sample), pgrid_to_sample/distrib_to_sample.pdf(x)) * pgrid_proposal\n",
    "plt.plot(x[0], x[1], '.', c='black');\n",
    "plt.imshow(q, extent=[-xlim,xlim,-xlim,xlim], alpha=0.6, origin=\"lower\");\n",
    "plt.xlabel('x')\n",
    "plt.xlabel('y')\n",
    "plt.title('MH transition')\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54344eac-515a-4070-ab69-827f00e25c85",
   "metadata": {},
   "source": [
    "# Markov processes: a bit of theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a58ecb3-b3ed-45d9-a796-b28936f6bfd3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Definition\n",
    "\n",
    "Let $\\mathcal{S}$ denote the (finite) set of all state vectors $x$ [as an example, $x \\in \\mathcal{S}$ is a binary vector of length $n$ and thus $x$ can take on $2^n$ different values].\n",
    "\n",
    "Denote $p(x)$ a probability distribution over states [in our example, $p(x)$ is a vector of length $2^n$ with $\\sum_x p(x)=1$].\n",
    "\n",
    "In our context, a **Markov process** is a *discrete-time* stochastic dynamical process that is defined by a transition matrix $T(x'|x)$ that specifies the transition probability from an initial state $x$ to a final state $x'$ in a single time step [in the example, $T(x'|x)$ is a $2^n \\times 2^n$ matrix].\n",
    "\n",
    "Note that for any $x$, $T(x'|x)$ is a probability vector in $x'$:\n",
    "$$\\sum_{x'} T(x'|x)=1$$\n",
    "Matrices with this property (non-negative entries and normalized columns) are called **(left/column) stochastic matrices**.\n",
    "\n",
    "The Markov dynamics is given by\n",
    "$$p_{t+1}(x')=\\sum_x T(x'|x)p_t(x)$$\n",
    "\n",
    "where we assume we start from an initial state distribution $p_0(x)$. The probability update is thus a left-multiplication (right-multiplication would equivalently work with a right/row stochastic matrix)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1c7b916-7a54-409b-a753-0f9700185261",
   "metadata": {},
   "source": [
    "### Stationarity\n",
    "\n",
    "In the setting of a MCMC, we will build a Markov process\n",
    "$$p_0 \\to p_1 = T p_0 \\to p_2 = Tp_1 \\to p_n=T^n p_0\\to \\ldots$$\n",
    "\n",
    "that converges to a **stationary distribution** $p_\\infty$. Such vector is clearly invariant under the dynamics:\n",
    "$$T p_\\infty =p_\\infty$$\n",
    "in other words, $p_\\infty$ is a (normalized) eigenvector of $T$ with eigenvalue 1.\n",
    "\n",
    "**Do all Markov Chains have a stationary distribution?** Not necessarily (think of a simple random walk on an infinitely countable set of states).\n",
    "\n",
    "**If it exists, will $T^n$ converge?** Not necessarily, the process could be periodic.\n",
    "\n",
    "**If it exists, is the stationary distribution unique?** Not necessarily, there may be many of them. To ascertain uniqueness, we need to look at the spectrum of $T$.\n",
    "\n",
    "$T$ always has at least one eigenvalue 1. Indeed, we can write the column-normalization condition as\n",
    "$$\\boldsymbol{1}^T T=\\boldsymbol{1}^T$$\n",
    "with $\\boldsymbol{1}$ the vector with entries all $1$, implying that $T$ always has a left eigenvector with eigenvalue $1$.\n",
    "\n",
    "Furthermore, all eigenvalues $\\lambda_\\alpha$ of $T$ lie in the unit disc in the complex plane $|\\lambda_\\alpha|\\leq1$.\n",
    "\n",
    "Here's a \"proof by example\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bfb75c-c84c-43ce-bf30-5e946314d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "num_samples = 100\n",
    "\n",
    "Ts = torch.rand(num_samples, N, N)\n",
    "Ts = Ts / torch.sum(Ts, 1, keepdim=True) # using torch here to conveniently compute eigenvalues in parallel for all matrices\n",
    "eigs = torch.linalg.eigvals(Ts).numpy()\n",
    "\n",
    "plt.plot(np.real(eigs.flatten()), np.imag(eigs.flatten()), '.', alpha=0.5);\n",
    "plt.gca().set_aspect('equal')\n",
    "circle = np.exp(1j*np.linspace(0,2*np.pi,100))\n",
    "plt.plot(np.real(circle), np.imag(circle));\n",
    "plt.xlabel('Re λ')\n",
    "plt.ylabel('Im λ');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61fe694f-90f8-47d5-ad76-de1a8037b5be",
   "metadata": {},
   "source": [
    "If all entries of $T$ are positive, then its largest eigenvalue $\\lambda_{\\text{max}}=1$ is simple (i.e. its algebraic multiplicity is $1$), its associated eigenvector has positive entries, and all other eigenvalues lie stricly inside the unit disk.\n",
    "\n",
    "For general non-negative entries, the eigenvalue 1 could be degenerate: in such a case the stationary distribution is not unique and depends on the initial state.\n",
    "\n",
    "If for any pair of state $x'$ and $x$ there is a path from $x$ to $x'$ with non-zero probability, the Markov process is *irreducible*. In such a case, the process has a unique stationary distribution.\n",
    "  \n",
    "In such a case $T$ has only one eigenvalue $1$ with a corresponding eigenvector possessing positive entries. The remaining eigenvalues are either inside the unit disk or have unit norm. By the **Perron-Frobenius** theorem, an irreducible Markov process $T$ of *periodicity $d$* has $d$ (simple) eigenvalues given by\n",
    "$$\\lambda_m=\\exp\\left(\\frac{2 \\pi i m}{d}\\right), m=0,\\ldots,d-1$$\n",
    "\n",
    "In absence of periodicity, an irreducible chain is **ergodic** - although some authors call all irreducible chains ergodic - and any initial condition converges to the stationary distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094bf3be-23b5-494f-b22f-c007489403ef",
   "metadata": {},
   "source": [
    "### *Bonus: Ergodicity and irreducibility*\n",
    "\n",
    "More generally, one can define irreducibility for a subset of states $\\mathcal{C} \\subset \\mathcal{S}$ if for any state\n",
    "$x \\in \\mathcal{C}$ there is a finite probability to visit any other state $x' \\in \\mathcal{C}$:\n",
    "$$x=x^0,x^1,\\ldots,x^k=x'$$\n",
    "with $T(x^i|x^{i-1})\\>0,i=1,\\ldots,k$.\n",
    "\n",
    "A subset of states $\\mathcal{C} \\subset \\mathcal{S}$ is called *closed* when\n",
    "the Markov process can never escape from $\\mathcal{C}$, once entered:\n",
    "$$T(x'|x)=0~~~\\mbox{for all}~~x \\in \\mathcal{C}, x' \\notin \\mathcal{C}.$$\n",
    "In general, we can decompose the state space $\\mathcal{S}$ uniquely\n",
    "into closed irreducible subsets $\\mathcal{C}_i$\n",
    "$$\\mathcal{S} = \\mathcal{T} \\cup \\mathcal{C}_1 \\cup \\mathcal{C}_2 \\ldots,$$\n",
    "where $\\mathcal{T}$ is a set of *transient states*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db742126-88b9-4d67-b249-5cd968a4e8ab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### *Bonus: Characteristic times*\n",
    "\n",
    "The characteristic time it takes to reach stationarity is determined by the other eigenvalues of $T$.\n",
    "\n",
    "Let us denote the eigenvalues and left and right eigenvectors of $T$ by\n",
    "$ \\lambda_\\alpha, l_\\alpha, r_\\alpha$ [In our example we would have $\\alpha=1,\\ldots,2^n$, respectively. Also, the number of eigenvalues of $T$ can be generically less than $2^n$. However, for our purposes we can ignore this case.].\n",
    "\n",
    "In matrix notation we have [$\\dagger$ denotes complex conjugation and transpose]:\n",
    "$$T r_\\alpha=\\lambda_\\alpha r_\\alpha$$\n",
    "$$l_\\alpha^\\dagger T =\\lambda_\\alpha l_\\alpha^\\dagger$$\n",
    "Since $T$ is a non-symmetric matrix, the left and right eigenvectors\n",
    "are different, non-orthogonal and complex valued. The eigenvalues are complex valued.\n",
    "Under rather general conditions each set of eigenvectors spans a\n",
    "non-orthogonal basis of $C^{N}$.\n",
    "These two bases are dual in the sense that:\n",
    "$$l_\\alpha^\\dagger r_\\beta= \\delta_{\\alpha\\beta}.$$\n",
    "\n",
    "We can expand $T$ on the basis of its eigenvectors:\n",
    "$$T=\\sum_{\\alpha=1}^{N} \\lambda_\\alpha r_\\alpha l_\\alpha^\\dagger$$\n",
    "\n",
    "It is easy to check that this satisfies the eigen equations:$$T r_\\beta =\\sum_\\alpha \\lambda_\\alpha r_\\alpha l^\\dagger_\\alpha r_\\beta =\\sum_\\alpha \\lambda_\\alpha r_\\alpha \\delta_{\\alpha\\beta}=\\lambda_\\beta r_\\beta$$\n",
    "and similarly $l^\\dagger_\\beta T=\\lambda_\\beta l^\\dagger_\\beta$.\n",
    "\n",
    "In the ergodic case with periodicity 1:\n",
    "$$p_t=Tp_{t-1}=\\ldots=T^t p_0=\\sum_\\alpha \\lambda_\\alpha^t r_\\alpha (l_\\alpha^\\dagger p_0) =p_\\infty + \\sum_{\\alpha >1}\\lambda_\\alpha^t r_\\alpha (l_\\alpha^\\dagger p_0)$$We can write$$\\lambda_\\alpha^t = |\\lambda_\\alpha|^t e^{i\\phi_\\alpha t} = e^{-t/\\tau_\\alpha} e^{i\\phi_\\alpha t}\\qquad \\tau_\\alpha= \\frac{-1}{\\log| \\lambda_\\alpha|}$$\n",
    "The characteristic time to converge to the stationary distribution is determined by the largest $|\\lambda_\\alpha|$.\n",
    "\n",
    "With higher periodicity the solution oscillates asymptotically:\n",
    "$$p_t=\\sum_{\\alpha, |\\lambda_\\alpha|=1} \\lambda_\\alpha^t r_\\alpha (l_\\alpha^\\dagger p_0)+\\sum_{\\alpha, |\\lambda_\\alpha|<1} \\lambda_\\alpha^t r_\\alpha (l_\\alpha^\\dagger p_0)\\quad\\to\\quad \\sum_{m=0}^{d-1} e^{2\\pi i mt/d} r_m (l^\\dagger_m p_0)$$For instance $p_0=\\frac{1}{2}(r_0 +r_1)$ and $d=4$:$$p_t(x) = \\frac{1}{2} (r_0(x) + i^t r_1(x))$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cf9b2c3-9ae3-47fe-99e4-0b0366ce4ac7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### *Bonus: Non-ergodic behavior*\n",
    "\n",
    "A non-irreducible or non-ergodic\n",
    "Markov process has more than one eigenvalue 1 and\n",
    "therefore more than one left and right eigenvector with eigenvalue 1.\n",
    "Let us denote these eigenvectors by\n",
    "$l_1,\\ldots,l_k$ and $r_1,\\ldots,r_k$, respectively. Any linear combination of the\n",
    "right eigenvectors\n",
    "$$p_\\infty=\\sum_{\\alpha=1}^k \\rho_\\alpha r_\\alpha$$\n",
    "is therefore a stationary\n",
    "distribution, with parameters $\\rho_\\alpha$ such that $p_\\infty(x)\\ge 0$ for all\n",
    "$x$ and proper normalization: $\\sum_x p_\\infty(x)=1$. Thus, there exists a manifold of\n",
    "dimension $k-1$ of stationary distributions.\n",
    "\n",
    "The $k$ left eigenvectors with\n",
    "eigenvalue 1 encode *invariants* of the dynamics\n",
    "$$l_\\alpha^\\dagger p_{t+1}=l_\\alpha^\\dagger T p_t = l_\\alpha^\\dagger p_t \\qquad \\alpha=1,\\ldots,k$$\n",
    "Since $l_1\\propto (1,\\ldots,1)$ the first invariant simply ensures invariance of normalisation $\\sum_x p_{t+1}(x)=\\sum_x p_t(x)$.\n",
    "Thus,\n",
    "$$l_\\alpha^\\dagger p_0=l_\\alpha^\\dagger p_\\infty\\qquad \\alpha=1,\\ldots,k$$\n",
    "\n",
    "The invariants determine uniquely the stationary distribution in terms of the initial conditions.\n",
    "$$p_\\infty=\\sum_{\\alpha=1}^k \\rho_\\alpha r_\\alpha =\\sum_{\\alpha=1}^k (l_\\alpha^\\dagger p_0) r_\\alpha$$\n",
    "because $\\rho_\\alpha=l_\\alpha^\\dagger p_\\infty=l_\\alpha^\\dagger p_0$.\n",
    "\n",
    "Note, that in the ergodic case ($k=1$) the dependence on the initial\n",
    "state disappears, as it should, since $l_1^\\dagger p_0=1$ for any initial\n",
    "distribution $p_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80234c08-6762-45c3-a6ac-9e79abab9e23",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Detailed balance\n",
    "\n",
    "The Markov process $T$ satisfies Detailed Balance (DB) if $$\\exists p$$such that\n",
    "$$T(x|x')p(x')=T(x'|x)p(x)~~\\mbox{for all}~~x,x'.$$\n",
    "\n",
    "The crucial property of DB is that:\n",
    "$$\\text{DB}\\implies\\text{stationarity}$$\n",
    "since \n",
    "$$\\sum_{x'}T\\left(x|x'\\right)p\\left(x'\\right)=\\sum_{x'}T\\left(x'|x\\right)p\\left(x\\right)=p\\left(x\\right)$$\n",
    "but in general\n",
    "$$\\text{DB}\\nLeftarrow\\text{stationarity}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d189401-1a9c-4b05-8e4b-9fc67958683a",
   "metadata": {},
   "source": [
    "# Summary of Markov processes\n",
    "\n",
    "The Markov process can be analysed in terms of the eigenvalues and\n",
    "eigenvectors of the transition matrix $T$.\n",
    "\n",
    "1.  There exists always an eigenvalue $\\lambda=1$.\n",
    "      * If this eigenvalue is non-degenerate, the Markov process is called **ergodic**. The stationary distribution is unique and independent on the initial state.\n",
    "      * If this eigenvalue is degenerate, the Markov process is called **non-ergodic**. The stationary distribution is not unique and depends on the initial state.\n",
    "2.  Markov processes can have multiple eigenvalues $e^{2\\pi i m/d}, m=0,\\ldots, d-1$ and $|\\lambda|=1$. In this case it is called periodic with period $d$. In the most common case, the Markov process is non-periodic $d=1$.\n",
    "3.  Eigenvalues with norm close to 1 ($|\\lambda|=1-\\epsilon$, $\\epsilon$ small) imply long convergence times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece6ed2-0ed5-47e3-a80c-14c963bb5cc6",
   "metadata": {},
   "source": [
    "# Some examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb9e53a-baed-40ae-ad53-ae3a15ba50ec",
   "metadata": {},
   "source": [
    "#### Stationary distribution for a random walk on a lattice with reflecting boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458cb3da-29c8-4734-8948-357a14662f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "num_steps = 1000\n",
    "num_samples = 5000\n",
    "\n",
    "x0 = 17\n",
    "x = np.ones(num_samples) * x0\n",
    "xs = np.zeros((num_steps, num_samples))\n",
    "for t in range(num_steps):\n",
    "    xs[t] = x\n",
    "    x = x + 2 * np.random.randint(2, size=num_samples) - 1\n",
    "    x = np.clip(x, 0, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec4d2b-a7f3-4b4d-ab0c-a1f0fc4361dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transition matrix\n",
    "T = 0.5 * (np.eye(N+1, k=1) + np.eye(N+1, k=-1))\n",
    "T[0,0] = 0.5\n",
    "T[N,N] = 0.5\n",
    "\n",
    "# compute eigenvalues and eigenvectors (use a function specific for hermitian matrices to directly get sorted eigevalues)\n",
    "eigs, U = np.linalg.eigh(T)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(T, cmap='hot');\n",
    "plt.title(\"transition matrix T\")\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(eigs, '.-')\n",
    "plt.xlabel('i')\n",
    "plt.ylabel('eig(T)')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(U[:,-1]);\n",
    "plt.xlabel('i')\n",
    "plt.ylabel('eigenvector with eig = 1')\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df8f1e-f378-4a53-a855-878ed6e0ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evolve probability of states\n",
    "p = np.zeros(N+1)\n",
    "p[x0] = 1\n",
    "ps = np.zeros((num_steps, N+1))\n",
    "for t in range(num_steps):\n",
    "    ps[t] = p\n",
    "    p = T @ p\n",
    "\n",
    "# visualize evolution of probability over states\n",
    "num_to_show = 10\n",
    "t_to_show = np.logspace(0, np.log10(num_steps), num_to_show, dtype=int) - 1\n",
    "\n",
    "fig, axes = plt.subplots(num_to_show, figsize=(4, 2 * num_to_show))\n",
    "for i, t in enumerate(t_to_show):\n",
    "    axes[i].hist(xs[t], bins=np.arange(N+1+1)-0.5, density=True, alpha=0.5, label='data');\n",
    "    axes[i].plot(ps[t], '.-', label='theory');\n",
    "    axes[i].set_title(f't = {t}')\n",
    "    axes[i].set_xlabel('x')\n",
    "    axes[i].set_ylabel('p(x)');\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37605a72-e984-45f9-8355-25d8f90552bf",
   "metadata": {},
   "source": [
    "#### The simplest periodic Markov Chain\n",
    "\n",
    "In this example, state 1 and 2 interchange at each step. Correspondingly, the chain has two eigenvalues on the unit disk (period $d=2$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e88ec5f-1165-441e-9203-c96c40db8152",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.array([[0,1], [1,0]])\n",
    "v, U = np.linalg.eig(T)\n",
    "print(\"T:\")\n",
    "print(T)\n",
    "print(\"eigenvalues:\", v)\n",
    "print(\"eigenvectors:\", U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec56446e-b572-46b6-9e63-e2f094f14a19",
   "metadata": {},
   "source": [
    "#### A slightly more complicate periodic Markov chain: random walk on the hypercube in $n$ dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a0713cc-1f91-4f39-8495-ad8980d0931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct transition matrix for a random walk on an hypercube\n",
    "n = 3\n",
    "N = 2**n\n",
    "allxs = np.zeros((2**n,n))\n",
    "for ix, x in enumerate(itertools.product(*[[-1.,1.] for i in range(n)])):\n",
    "    allxs[ix] = x\n",
    "Δxs = np.abs(allxs[:,None] - allxs[None]).sum(-1)\n",
    "T = (Δxs == 2) / n\n",
    "\n",
    "# compute eigenvalues and eigenvectors (use a function specific for hermitian matrices to directly get sorted eigevalues)\n",
    "eigs, U = np.linalg.eig(T)\n",
    "p1 = U[:,np.abs(eigs-1)<1e-10]\n",
    "pm1 = U[:,np.abs(eigs+1)<1e-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e841467-da25-4092-a6c1-12ed8c8291b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize transition matrix, eigenvalues and eigenvectors\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(T)\n",
    "plt.title('T')\n",
    "plt.title(\"transition matrix T\")\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(eigs, '.-')\n",
    "plt.xlabel('i')\n",
    "plt.ylabel('eig(T)')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(p1, '.-', label='eigv λ = 1');\n",
    "plt.plot(pm1,'.-', label='eigv λ = -1');\n",
    "plt.plot(np.prod(allxs, 1), ':.', c='gray', label=\"parity\")\n",
    "plt.xlabel('i')\n",
    "plt.ylabel('eigenvectors of T')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e1b428-91d1-49c4-ad9d-2767ddea0613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evolve probability of states\n",
    "# try starting from a random distribution\n",
    "num_steps = 100\n",
    "p = np.random.rand(N)\n",
    "p /= p.sum()\n",
    "# start from a uniform distribution\n",
    "# p = np.ones(N) / N\n",
    "\n",
    "ps = np.zeros((num_steps, N))\n",
    "for t in range(num_steps):\n",
    "    ps[t] = p\n",
    "    p = T @ p\n",
    "\n",
    "# visualize last steps\n",
    "last = 10\n",
    "fig, axes = plt.subplots(last, figsize=(3, 1 * last))\n",
    "for i in range(last):\n",
    "    axes[i].plot(ps[num_steps-i-1]);\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a31847-3d1e-47a4-94ea-74b49c8856a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the random walk by randomly flipping one variable at each step\n",
    "num_samples = 10\n",
    "\n",
    "x = 2 * np.random.randint(2, size=(num_samples, n)) - 1\n",
    "\n",
    "xs = np.zeros((num_steps, num_samples, n))\n",
    "for t in range(num_steps):\n",
    "    xs[t] = x\n",
    "    idxs = np.random.choice(n, size=num_samples)\n",
    "    x[np.arange(num_samples), idxs] *= -1 \n",
    "\n",
    "# plot parities of configurations through time\n",
    "parities = np.prod(xs, -1)\n",
    "upto = 10\n",
    "plt.plot(parities[:upto, parities[0]>0], c='black');\n",
    "plt.plot(parities[:upto, parities[0]<0], c='red');\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('parity');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8378fe4-2193-42de-a322-7d8f48292a3d",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e546f-2ef9-45d1-95ad-cc38540b4465",
   "metadata": {},
   "source": [
    "[[1]](https://www.youtube.com/watch?v=5ZLtcTZP2js)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
